package run_cmd

import (
	"context"
	"flag"
	"fmt"
	"glesha/archive"
	"glesha/backend"
	"glesha/backend/aws"
	"glesha/config"
	"glesha/database"
	"glesha/database/model"
	"glesha/database/repository"
	"glesha/file_io"
	L "glesha/logger"
	"strconv"
	"strings"
	"time"
)

type RunCmdEnv struct {
	DB                *database.DB
	TaskId            int64
	Task              *model.Task
	TaskRepo          repository.TaskRepository
	UploadRepo        repository.UploadRepository
	UploadBlockRepo   repository.UploadBlockRepository
	FileCatalogRepo   repository.FileCatalogRepository
	MaxConcurrentJobs int
}

func Execute(ctx context.Context, args []string) error {
	// parse cli args
	runCmdEnv := &RunCmdEnv{}
	err := parseFlags(args, runCmdEnv)
	if err != nil {
		return err
	}

	// initialize db connection
	dbPath, err := database.GetDBFilePath(ctx)
	if err != nil {
		return err
	}
	db, err := database.NewDB(dbPath)
	if err != nil {
		return err
	}
	defer db.Close(ctx)
	L.Debug(fmt.Sprintf("Found database at: %s", dbPath))
	runCmdEnv.DB = db
	err = runCmdEnv.DB.Init(ctx)
	if err != nil {
		return err
	}

	runCmdEnv.TaskRepo = repository.NewTaskRepository(db)
	runCmdEnv.UploadRepo = repository.NewUploadRepository(db)
	runCmdEnv.UploadBlockRepo = repository.NewUploadBlockRepository(db)
	runCmdEnv.FileCatalogRepo = repository.NewFileCatalogRepository(db)

	runCmdEnv.Task, err = runCmdEnv.TaskRepo.GetTaskById(ctx, runCmdEnv.TaskId)
	if err != nil {
		if err == database.ErrDoesNotExist {
			return fmt.Errorf("task %d does not exist, for more information see 'glesha help add'", runCmdEnv.TaskId)
		}
		return err
	}
	L.Printf("%s", runCmdEnv.Task)
	err = config.Parse(runCmdEnv.Task.ConfigPath)
	if err != nil {
		return err
	}

	if config.Get().Autogenerated {
		L.Warn(config.GetAutoGenConfigWarning(runCmdEnv.Task.ConfigPath))
	}
	err = runTask(ctx, runCmdEnv)
	return err
}

func parseFlags(args []string, runCmdEnv *RunCmdEnv) error {
	const DEFAULT_MAX_JOBS = 1
	runCmd := flag.NewFlagSet("run", flag.ExitOnError)
	defaultLogLevel := L.GetLogLevel().String()
	defaultColorMode := L.GetColorMode().String()

	logLevel := runCmd.String("log-level", defaultLogLevel, "Set log level: debug info warn error panic")
	colorMode := runCmd.String("color", defaultColorMode, "Set color mode: auto always never")

	maxConcurrentJobs := runCmd.Int("jobs", DEFAULT_MAX_JOBS, "Set max workers to use for processing")
	runCmd.IntVar(maxConcurrentJobs, "j", DEFAULT_MAX_JOBS, "Set max workers to use for processing")
	runCmd.StringVar(logLevel, "L", defaultLogLevel, "Set log level: debug info warn error panic")

	runCmd.Usage = func() {
		PrintUsage()
	}
	err := runCmd.Parse(args)

	if err != nil {
		return err
	}

	err = L.SetColorModeFromString(*colorMode)
	if err != nil {
		return fmt.Errorf("could not set color mode to %s: %w", *colorMode, err)
	}
	if *colorMode != defaultColorMode {
		L.Info(fmt.Sprintf("Setting color mode to: %s", strings.ToUpper(*colorMode)))
	}
	err = L.SetLevelFromString(*logLevel)
	if err != nil {
		return err
	}
	if *logLevel != defaultLogLevel {
		L.Info(fmt.Sprintf("Setting log level to: %s", strings.ToUpper(*logLevel)))
	}

	nArgs := len(runCmd.Args())

	if nArgs < 1 {
		return fmt.Errorf("no task Id provided. For more information check 'glesha help run'")
	}
	if nArgs > 1 {
		return fmt.Errorf("too many arguments. For more information, check 'glesha help run'")
	}
	taskId, err := strconv.ParseInt(runCmd.Arg(0), 10, 64)
	if err != nil {
		return err
	}

	runCmdEnv.TaskId = taskId
	runCmdEnv.MaxConcurrentJobs = *maxConcurrentJobs
	return err
}

func runTask(ctx context.Context, runCmdEnv *RunCmdEnv) error {
	t := runCmdEnv.Task
	if t == nil {
		return fmt.Errorf("no task to run")
	}
	mustRearchive := false
	switch t.Status {
	case model.TASK_STATUS_QUEUED,
		model.TASK_STATUS_ARCHIVE_RUNNING,
		model.TASK_STATUS_ARCHIVE_ABORTED,
		model.TASK_STATUS_ARCHIVE_PAUSED:
		mustRearchive = true
	}

	var archiver archive.Archiver
	var err error
	switch t.ArchiveFormat {
	case config.AF_TARGZ:
		archiver, err = archive.NewTarGzArchiver(t)
		if err != nil {
			return err
		}
		archivePath := archiver.GetArchiveFilePath(ctx)
		L.Info("Planning archive")
		err = archiver.Plan(ctx)
		if err != nil {
			return err
		}
		L.Println("Plan Archive: OK")
		err = archive.IsValidTarGz(archivePath)
		if err != nil {
			mustRearchive = true
			L.Debug(err)
			L.Debug(fmt.Sprintf("Existing archive %s is not valid, starting fresh", archivePath))
		}
		info := archiver.GetInfo(ctx)
		if int64(info.SizeInBytes) != t.TotalSize {
			L.Info("Rearchiving because input_path contents have changed since last run")
			mustRearchive = true
		}
	default:
		return fmt.Errorf("archive format %s is not supported yet", t.ArchiveFormat.String())
	}

	if mustRearchive {
		L.Info("Starting fresh because cannot continue from previous state")
		err = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_ARCHIVE_RUNNING)
		if err != nil {
			return err
		}
		err = archiver.Start(ctx, runCmdEnv.FileCatalogRepo, runCmdEnv.TaskRepo)
		if err != nil {
			_ = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_ARCHIVE_ABORTED)
			return err
		}
		select {
		case <-ctx.Done():
			_ = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_ARCHIVE_ABORTED)
			return fmt.Errorf("kill signal received, exiting")
		default:
		}
		err = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_ARCHIVE_COMPLETED)
		if err != nil {
			return err
		}
		err = runCmdEnv.TaskRepo.UpdateTaskContentInfo(ctx,
			runCmdEnv.TaskId, archiver.GetInfo(ctx))
		if err != nil {
			return err
		}
		L.Println("Create Archive: OK")
	} else {
		L.Info("Skipping Archiving because input_path contents have not changed since last run")
	}

	archivePath := archiver.GetArchiveFilePath(ctx)
	L.Printf("Archive: %s\n", archivePath)

	if runCmdEnv.Task.Provider != config.PROVIDER_AWS {
		return fmt.Errorf("unsupported provider: %v", runCmdEnv.Task.Provider.String())
	}

	var storageBackendFactory backend.StorageFactory = &aws.AWSFactory{}
	storageBackend, err := storageBackendFactory.NewStorageBackend()
	if err != nil {
		return err
	}

	err = storageBackend.CreateResourceContainer(ctx)
	if err != nil {
		return err
	}
	L.Println("Upload::CreateResourceContainer OK")

	existingUpload, err := runCmdEnv.UploadRepo.GetUploadByTaskId(ctx, runCmdEnv.TaskId)

	var uploadId int64

	if err != nil && err == database.ErrDoesNotExist {
		uploadRes, err2 := storageBackend.CreateUploadResource(ctx,
			runCmdEnv.Task.Key(), archivePath)
		if err2 != nil {
			return err2
		}
		L.Println("Upload::CreateUploadResource OK")
		archiveFileInfo, err2 := file_io.GetFileInfo(archivePath)
		if err2 != nil {
			return err2
		}

		blockSizeInBytes := uploadRes.BlockSizeInBytes
		archiveFileSize := int64(archiveFileInfo.Size)
		var totalBlocks int64 = 1
		if blockSizeInBytes > 0 {
			totalBlocks = (archiveFileSize + blockSizeInBytes - 1) / blockSizeInBytes
		}

		err2 = storageBackend.IsBlockSizeOK(blockSizeInBytes, archiveFileSize)
		if err2 != nil {
			return fmt.Errorf("failed to partition file: %w", err)
		}
		now := time.Now()
		uploadId, err2 = runCmdEnv.UploadRepo.CreateUpload(
			ctx,
			runCmdEnv.TaskId,
			uploadRes.Metadata.Json,
			uploadRes.Metadata.SchemaVersion,
			archivePath,
			int64(archiveFileInfo.Size),
			archiveFileInfo.ModifiedAt,
			totalBlocks,
			blockSizeInBytes,
			now,
			now,
		)

		if err2 != nil {
			return fmt.Errorf("failed to save upload information: %w", err)
		}
		L.Printf("Upload::CreateUploadResource OK (upload_id: %d)\n", uploadId)
		err = nil
	} else if err != nil {
		return fmt.Errorf("could not get upload for task id %d: %w", runCmdEnv.TaskId, err)
	} else {
		L.Info("Skipping creating a new upload because upload already exists for a task")
		uploadId = existingUpload.Id
	}
	L.Println(fmt.Sprintf("Task(%d) now has upload Id: %d", runCmdEnv.TaskId, uploadId))
	if err != nil {
		return err
	}

	_ = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_UPLOAD_RUNNING)
	_ = runCmdEnv.UploadRepo.UpdateStatus(ctx, uploadId, model.UPLOAD_STATUS_RUNNING)

	err = storageBackend.UploadResource(
		ctx,
		runCmdEnv.TaskRepo,
		runCmdEnv.UploadRepo,
		runCmdEnv.UploadBlockRepo,
		runCmdEnv.MaxConcurrentJobs,
		uploadId,
	)

	if err != nil {
		_ = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_UPLOAD_ABORTED)
		_ = runCmdEnv.UploadRepo.UpdateStatus(ctx, uploadId, model.UPLOAD_STATUS_FAILED)
		return err
	}
	_ = runCmdEnv.TaskRepo.UpdateTaskStatus(ctx, runCmdEnv.TaskId, model.TASK_STATUS_UPLOAD_COMPLETED)
	L.Printf("Upload Archive: OK\n")
	return nil
}
